# -*- coding: utf-8 -*-
"""lda_topic_modeling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17yeArRXSCeb9kiaEOxJYCOpXr-wjZ05v

Module includes folowing functionality:
 - Topic modeling with LDA
 - Hyperparameter tuning
 - Coherence measure calculation
 - LDA topic model visualiszation
"""

#from google.colab import drive

#root_path = '/content/drive'
#drive.mount(root_path)

import os

import numpy as np
import pandas as pd

import gensim
from gensim import corpora, models 

from gensim.models.coherencemodel import CoherenceModel
from gensim import similarities

from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

class LDAModeler():
    def __init__(self, data, column_name='normalized_article', dict_filter_no_below = 3, dict_filter_no_above = 0.7, coherence_measure = 'c_v'):
        self.coherence_measure = coherence_measure
        self.dictionary = None
        self.norm_tokenized_corpus = None
        self.corpus = None
        
    def data_preprocessing(self, data: pd.DataFrame, column_name = 'normalized_article', dict_filter_no_below = 3, dict_filter_no_above = 0.7 ):
        normalized_article = data.loc[0:,column_name].tolist()
        self.norm_tokenized_corpus = [row.split() for row in normalized_article]
        self.dictionary = corpora.Dictionary(self.norm_tokenized_corpus)
        self.dictionary.filter_extremes(no_below=dict_filter_no_below, no_above=dict_filter_no_above)

        self.corpus = [self.dictionary.doc2bow(text) for text in self.norm_tokenized_corpus]
        #return norm_tokenized_corpus, corpus, dictionary

    def create_lda_model(self, num_topics = 0):
        if num_topics == 0:
            lda_model = models.LdaModel(
                                corpus=self.corpus, 
                                id2word=self.dictionary, 
                                random_state=1, 
                                chunksize=1000, 
                                passes=10, 
                                alpha='auto', 
                                per_word_topics=True
                                )
        else:

            lda_model = models.LdaModel(
                                corpus=self.corpus, 
                                id2word=self.dictionary, 
                                num_topics=num_topics,
                                random_state=1, 
                                chunksize=1000, 
                                passes=10, 
                                alpha='auto', 
                                per_word_topics=True
                                )
        return lda_model

    def save_lda_model(self, lda_model, filepath):
        lda_model.save(filepath)
        
    def load_lda_model(self, filepath):
        lda_model = models.LdaModel.load('/content/drive/MyDrive/FU_NLP_Project/models/lda_model_')
        return lda_model

    def compute_coherence(self, lda_model):
        coherence_model = CoherenceModel(model=lda_model, texts=self.norm_tokenized_corpus, corpus = self.corpus, dictionary=self.dictionary, coherence=self.coherence_measure)
        return coherence_model.get_coherence()

    def show_wordcloud(self, data, title = None):
        stopwords = set(STOPWORDS)
        wordcloud = WordCloud(
            background_color='white',
            stopwords=stopwords,
            max_words=200,
            max_font_size=40, 
            scale=3,
            random_state=1 # chosen at random by flipping a coin; it was heads
        ).generate(str(data))

        fig = plt.figure(1, figsize=(8, 8))
        plt.axis('off')
        if title: 
            fig.suptitle(title, fontsize=14)
            fig.subplots_adjust(top=2.3)

        plt.imshow(wordcloud)
    
    def show_lda_topics_as_text(self, lda_model, num_words=10):
        for topic_id in range(lda_model.num_topics):
            topk = lda_model.show_topic(topic_id, num_words)
            topk_words = [ w for w, _ in topk ]
            print('{}: {}'.format(topic_id, ' '.join(topk_words)))

    def show_lda_topics_as_cloud(self, lda_model, num_topics=6, num_words=20):
        for topic_id, topic in lda_model.print_topics(num_topics=num_topics, num_words=num_words):
            print('Topic #'+str(topic_id+1)+':')
            print(topic)
            self.show_wordcloud(topic)
            plt.show()

    def compute_cv_optim(self, num_topics):
        lda_model = gensim.models.LdaMulticore(corpus=self.corpus,
                                            id2word=self.dictionary,
                                            num_topics=num_topics, 
                                            random_state=1,
                                            chunksize=3000,
                                            passes=10)
        
        coherence_model_lda = CoherenceModel(model=lda_model, texts=self.norm_tokenized_corpus, corpus = self.corpus, dictionary=self.dictionary, coherence=self.coherence_measure)
        
        return coherence_model_lda.get_coherence()
    
    def tune_hyperparams (self, num_topics):
        model_results = {'Topics': [],
                    'Coherence': []
                    }
        for n in num_topics:
            cv = self.compute_cv_optim(num_topics=n)
            print("Num of topics:", n , " Coherence measure: ", cv)
            model_results['Topics'].append(n)
            model_results['Coherence'].append(cv)
        pd_results = pd.DataFrame(model_results)
            
        return pd_results

